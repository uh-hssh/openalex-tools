{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616fbc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyalex\n",
    "from pyalex import Authors\n",
    "from pyalex import Works\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give email to use polite pool, otherwise leave blank\n",
    "email = input()\n",
    "pyalex.config.email = email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98671bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"\"\n",
    "source_dir = \"\"\n",
    "\n",
    "if not os.path.exists(data_dir): os.makedirs(data_dir)\n",
    "if not os.path.exists(source_dir): os.makedirs(source_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e97250",
   "metadata": {},
   "source": [
    "## Download OA author ids using names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47483310",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_sources = pd.read_csv(source_dir + input() + \".csv\")\n",
    "authors_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of author objects grouped by display name\n",
    "author_objects = []\n",
    "\n",
    "for a in authors_sources['name']:\n",
    "    print(a)\n",
    "    author_objects.append( Authors().search_filter(display_name=a).get() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get author names and OA ids and save to list â€“ need to check these by hand!\n",
    "\n",
    "authors_ids = []\n",
    "\n",
    "for author_list in authors_objects:   \n",
    "    for author in author_list:\n",
    "        authors_ids.append( (author['display_name'], author['id'], author['relevance_score'])  )\n",
    "        \n",
    "authors_ids_df = pd.DataFrame( authors_ids, columns=['name', 'id', 'relevance'] )\n",
    "\n",
    "authors_ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv for hand-checking\n",
    "authors_ids_df.to_csv(source_dir + 'authors_ids_unchecked.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ec1787",
   "metadata": {},
   "source": [
    "## Download works using OA author ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_ids = pd.read_csv(source_dir + input() + \".csv\")\n",
    "authors_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_works = {}\n",
    "\n",
    "for i, row in authors_ids.iterrows():\n",
    "    \n",
    "    author_name = row[0]\n",
    "    author_id = row[1].replace('https://openalex.org/', '')\n",
    "    \n",
    "    print(i, author_name, 'https://openalex.org/' + author_id)\n",
    "    \n",
    "    paginator = Works().filter( authorships={\"author\" : {'id' : author_id}} ).paginate(per_page=200)\n",
    "    works = list(itertools.chain.from_iterable(paginator))\n",
    "    \n",
    "    if author_name not in authors_works:\n",
    "        authors_works[author_name] = {author_id : works}\n",
    "    else:\n",
    "        authors_works[author_name][author_id] = works\n",
    "        \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d38e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(authors_works.keys()))\n",
    "print( authors_works.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b3b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump works as dict\n",
    "with open(data_dir + 'authors_works.p', 'wb') as fp:\n",
    "    pickle.dump(authors_works, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e153b",
   "metadata": {},
   "source": [
    "## List works by css author and references by css paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff531f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + 'authors_works.p', 'rb') as fp:\n",
    "    authors_works = pickle.load(fp)\n",
    "\n",
    "authors_works.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea82b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_list = []\n",
    "works_references = {}\n",
    "\n",
    "for author_name in authors_works:\n",
    "    \n",
    "    # For authors with multiple OA ids, use just one in data\n",
    "    author_common_id = list( authors_works[author_name].keys() )[0]\n",
    "    \n",
    "    # Iterate over author OA ids and works\n",
    "    for author_orig_id in authors_works[author_name]:           \n",
    "        \n",
    "        for work in authors_works[author_name][author_orig_id]:\n",
    "            \n",
    "            # Get OA id of the publication source if exists\n",
    "            try: source_id = work['primary_location']['source']['id']\n",
    "            except: source_id = ''\n",
    "            \n",
    "            work_id = work['id'].replace('https://openalex.org/', '')\n",
    "                \n",
    "            # Create work data tuple\n",
    "            d = (\n",
    "                author_orig_id, # Store original OA author id\n",
    "                author_common_id, \n",
    "                author_name,\n",
    "                work_id,\n",
    "                work['doi'],\n",
    "                work['title'],\n",
    "                work['type'],\n",
    "                source_id.replace('https://openalex.org/', ''),\n",
    "                work['publication_date'],\n",
    "                work['publication_year'],\n",
    "                work['cited_by_count']\n",
    "            )\n",
    "            \n",
    "            works_list.append( d )\n",
    "            \n",
    "            # Store references by work id\n",
    "            works_references[work_id] = work['referenced_works']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique papers by css authors\n",
    "len( works_references )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_df = pd.DataFrame(works_list, columns = [\n",
    "    'AuthorOrigId','AuthorId','AuthorName','PaperId','Doi',\n",
    "    'PaperTitle','DocType','SourceId','Date','Year','CitationCount'\n",
    "])\n",
    "\n",
    "works_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cbae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_df.to_csv(data_dir + 'cssAuthorPapersNoFamilies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce27239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump references as dict\n",
    "with open(data_dir + 'works_references.p', 'wb') as fp:\n",
    "    pickle.dump(works_references, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be60112",
   "metadata": {},
   "source": [
    "### Create family id for papers with multiple versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16529f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_df = pd.read_csv(data_dir + 'cssAuthorPapersNoFamilies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c52940",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_df['PaperTitle'] = works_df['PaperTitle'].fillna('')\n",
    "unique_papers = works_df.drop_duplicates('PaperId')\n",
    "len(unique_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_versions = {}\n",
    "\n",
    "for paper in unique_papers.itertuples():\n",
    "        \n",
    "    if paper.PaperTitle:\n",
    "        \n",
    "        norm_title = paper.PaperTitle.lower().strip().translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        if norm_title not in paper_versions:\n",
    "            paper_versions[norm_title] = [paper.PaperId]\n",
    "        else:\n",
    "            paper_versions[norm_title].append(paper.PaperId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f3b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_families = []\n",
    "\n",
    "for paper in unique_papers.itertuples(index=False):\n",
    "            \n",
    "    if paper.PaperTitle:\n",
    "        \n",
    "        norm_title = paper.PaperTitle.lower().strip().translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        versions = paper_versions[norm_title]\n",
    "                \n",
    "        if len(versions) > 1:\n",
    "            paper = paper + (''.join(versions),)\n",
    "        else:\n",
    "            paper = paper + (None,)\n",
    "    \n",
    "    paper_families.append( paper )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd613c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_papers = pd.DataFrame( paper_families, columns = list( works_df.columns ) + ['FamilyId'] )\n",
    "unique_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77431bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_df_families = pd.merge( works_df, unique_papers[['PaperId','FamilyId']], how='left' )\n",
    "works_df_families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_df.to_csv(data_dir + 'cssAuthorPapers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031819a",
   "metadata": {},
   "source": [
    "## Get references by css paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + 'works_references.p', 'rb') as fp:\n",
    "    works_references = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References count\n",
    "ref_ids = [ref.replace('https://openalex.org/', '') for refs in works_references.values() for ref in refs]\n",
    "unique_ref_ids = list( set( ref_ids ) )\n",
    "\n",
    "print( len( ref_ids ) )\n",
    "print( len( unique_ref_ids ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9691099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump unique reference ids \n",
    "with open(data_dir + 'unique_references_ids.p', 'wb') as fp:\n",
    "    pickle.dump(unique_ref_ids, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0790e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/eschares/OpenAlex-CitedReferences/blob/main/notebooks/1-Pull_the_data_OpenAlex-citedreferences.ipynb\n",
    "import requests\n",
    "\n",
    "def get_references(reference_ids, chunk_size, mailto):\n",
    "    session = requests.Session()\n",
    "    \n",
    "    for i in range(0, len(reference_ids), chunk_size):\n",
    "        chunk = reference_ids[i:i + chunk_size]\n",
    "        \n",
    "        query = \"|\".join( chunk )\n",
    "        \n",
    "        api_url = 'https://api.openalex.org/works?filter=openalex:' + query\n",
    "        api_url += '&per_page=' + str( chunk_size ) + '&mailto=' + mailto\n",
    "                \n",
    "        yield session.get(api_url).json()['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7124a",
   "metadata": {},
   "source": [
    "### Download unique references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e768f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = len(unique_ref_ids)\n",
    "per_page = 50\n",
    "number_of_pages_needed = int(count / per_page) + (count % per_page > 0)\n",
    "print(f\"number of requests needed (with per_page set to {per_page}): {number_of_pages_needed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4dbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "unique_references_data = []\n",
    "results_per_page = get_references(unique_ref_ids, 50, email)\n",
    "\n",
    "# call OpenAlex API \n",
    "for i, results in enumerate(results_per_page):\n",
    "    \n",
    "    if i % 100 == 0: print(f'{i} requests sent')\n",
    "        \n",
    "    for work in results:\n",
    "        \n",
    "        # Get OA id of the publication source if exists\n",
    "        try: source_id = work['primary_location']['source']['id']\n",
    "        except: source_id = ''\n",
    "            \n",
    "        author_names = [a['author']['display_name'] for a in work['authorships']]\n",
    "        author_ids = [a['author']['id'].replace('https://openalex.org/', '') for a in work['authorships']]\n",
    "        \n",
    "        # Create reference data tuple\n",
    "        r = (\n",
    "            work['id'].replace('https://openalex.org/', ''),\n",
    "            work['doi'],\n",
    "            work['title'],\n",
    "            author_names,\n",
    "            author_ids,\n",
    "            work['type'],\n",
    "            source_id.replace('https://openalex.org/', ''),\n",
    "            work['publication_date'],\n",
    "            work['publication_year'],\n",
    "            work['cited_by_count']\n",
    "        )\n",
    "        \n",
    "        unique_references_data.append( r )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f349cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(unique_references_data), \"/\", len(unique_ref_ids) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0badce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump unique references as list\n",
    "with open(data_dir + 'unique_references_data.p', 'wb') as fp:\n",
    "    pickle.dump(unique_references_data, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88808afa",
   "metadata": {},
   "source": [
    "### Try to get missing refs one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + 'unique_references_ids.p', 'rb') as fp:\n",
    "    unique_ref_ids = pickle.load(fp)\n",
    "\n",
    "with open(data_dir + 'unique_references_data.p', 'rb') as fp:\n",
    "    unique_references_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92844cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ref_ids = []\n",
    "\n",
    "ref_ids = set( [ref[0] for ref in unique_references_data] )\n",
    "\n",
    "for ref in unique_ref_ids:\n",
    "    if ref not in ref_ids:\n",
    "        missing_ref_ids.append( ref )\n",
    "\n",
    "len( missing_ref_ids )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb753e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "missing_references = []\n",
    "errors = []\n",
    "\n",
    "for i, ref_id in enumerate(missing_ref_ids):\n",
    "    \n",
    "    if i % 10 == 0: print(f'{i} requests sent with', len(errors), 'errors', end='\\r' )\n",
    "    \n",
    "    try: \n",
    "        work = Works()[ref_id]\n",
    "    except: \n",
    "        errors.append(ref_id)\n",
    "        continue\n",
    "    \n",
    "    if work['title'] == 'Deleted Work':\n",
    "        continue\n",
    "    \n",
    "    # Get OA id of the publication source if exists\n",
    "    try: source_id = work['primary_location']['source']['id']\n",
    "    except: source_id = ''\n",
    "        \n",
    "    author_names = [a['author']['display_name'] for a in work['authorships']]\n",
    "    author_ids = [a['author']['id'].replace('https://openalex.org/', '') for a in work['authorships']]\n",
    "        \n",
    "    # Create reference data tuple\n",
    "    r = (\n",
    "        ref_id,\n",
    "        work['doi'],\n",
    "        work['title'],\n",
    "        author_names,\n",
    "        author_ids,\n",
    "        work['type'],\n",
    "        source_id.replace('https://openalex.org/', ''),\n",
    "        work['publication_date'],\n",
    "        work['publication_year'],\n",
    "        work['cited_by_count']\n",
    "    )\n",
    "        \n",
    "    missing_references.append( r )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe23199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len( missing_references )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c4de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_references_data = unique_references_data + missing_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0bc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(unique_references_data), '/', len(unique_ref_ids) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ece42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump references as list\n",
    "with open(data_dir + 'unique_references_data.p', 'wb') as fp:\n",
    "    pickle.dump(unique_references_data, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bcfe03",
   "metadata": {},
   "source": [
    "### Create family id for references with multiple versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + 'unique_references_data.p', 'rb') as fp:\n",
    "    unique_references_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_version_key( ref ):\n",
    "    \n",
    "    ref_norm_title = ref[2].lower().strip()\n",
    "    ref_norm_title = ref_norm_title.translate(str.maketrans('', '', string.punctuation))\n",
    "    ref_author_ids = ', '.join( ref[4] )\n",
    "        \n",
    "    return( ref_norm_title + ', ' + ref_author_ids )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00525c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_versions = {}\n",
    "\n",
    "for ref in unique_references_data:\n",
    "    \n",
    "    ref_id = ref[0]\n",
    "    ref_title = ref[2]\n",
    "    \n",
    "    if ref_title:\n",
    "        \n",
    "        version_key = get_version_key( ref )\n",
    "        \n",
    "        if version_key not in ref_versions:\n",
    "            ref_versions[version_key] = [ref_id]\n",
    "        else:\n",
    "            ref_versions[version_key].append(ref_id)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_families = []\n",
    "\n",
    "for ref in unique_references_data:\n",
    "        \n",
    "    ref_title = ref[2]\n",
    "    \n",
    "    if ref_title:\n",
    "        \n",
    "        version_key = get_version_key( ref )\n",
    "        \n",
    "        versions = ref_versions[version_key]\n",
    "                \n",
    "        if len(versions) > 1:\n",
    "            ref = ref + (''.join(versions),)\n",
    "        else:\n",
    "            ref = ref + (None,)\n",
    "    \n",
    "    reference_families.append( ref  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c578e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump references with family ids as list\n",
    "with open(data_dir + 'unique_references_data_families.p', 'wb') as fp:\n",
    "    pickle.dump(reference_families, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0ce81",
   "metadata": {},
   "source": [
    "### Create full references dataset by combining css paper ids with referencing paper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + 'works_references.p', 'rb') as fp:\n",
    "    works_references = pickle.load(fp)\n",
    "\n",
    "with open(data_dir + 'unique_references_data_families.p', 'rb') as fp:\n",
    "    unique_references_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temp dictionary for querying css works that cite referenced papers\n",
    "refs_works = {}\n",
    "\n",
    "for paper_id in works_references:\n",
    "    \n",
    "    for ref_id in works_references[paper_id]:\n",
    "        \n",
    "        ref_id = ref_id.replace('https://openalex.org/', '')\n",
    "        \n",
    "        if ref_id not in refs_works:\n",
    "            refs_works[ref_id] = [paper_id]\n",
    "        else:\n",
    "            refs_works[ref_id].append(paper_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b896996",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_references_data = []\n",
    "\n",
    "for ref in unique_references_data:\n",
    "    \n",
    "    citing_work_ids = refs_works[ref[0]]\n",
    "    \n",
    "    for citing_id in citing_work_ids:\n",
    "        \n",
    "        full_references_data.append( ref + (citing_id,) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f91c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_refs_df = pd.DataFrame( full_references_data, columns = [\n",
    "    'PaperId','Doi','PaperTitle','Authors','AuthorIds','DocType',\n",
    "    'SourceId','Date','Year','CitationCount','FamilyId','PaperCitedId'\n",
    "] )\n",
    "\n",
    "full_refs_df = full_refs_df[[\n",
    "    'PaperCitedId','PaperId','FamilyId','Authors','AuthorIds','Doi','PaperTitle',\n",
    "    'DocType','SourceId','Date','Year','CitationCount'\n",
    "]]\n",
    "\n",
    "full_refs_df['Authors'] = full_refs_df['Authors'].apply( lambda a: ', '.join(a) )\n",
    "full_refs_df['AuthorIds'] = full_refs_df['AuthorIds'].apply( lambda a: ', '.join(a) )\n",
    "\n",
    "full_refs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_refs_df.to_csv(data_dir + 'papersReferredToByCssAuthors.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
